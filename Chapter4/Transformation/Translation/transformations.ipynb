{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Transformations**\n",
    "\n",
    "Transformation of an image refers to changing the behaviour or appearance in some way which includes translation, shearing, scaling, rotation, and other\n",
    "\n",
    "\n",
    "## **1. Translation**\n",
    "\n",
    "Translation is a specific type of transformation where the size, shape and orientation of the image does not change, instead the position of the image changes. It refers to shifting the image along X and Y axis. In OpenCV we can use cv2.warpAffine() with the translation matrix to perfom translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "dx = 50\n",
    "dy = 30\n",
    "\n",
    "def trackbar_translation(x):\n",
    "    dx = x\n",
    "    dy = 30\n",
    "    translation_matrix =  np.float32([[1, 0, dx], [0, 1, dy]])\n",
    "    translated_image = cv.warpAffine(img, translation_matrix, (img.shape[1], img.shape[0]))\n",
    "    cv.imshow('translation_window', translated_image)\n",
    "\n",
    "img = cv.imread(\"D:/OpenCV/Assets/newton.jpg\")\n",
    "\n",
    "# # translation matrix\n",
    "# translation_matrix = np.float32([[1, 0, dx], [0, 1, dy]])\n",
    "\n",
    "# translated_image = cv.warpAffine(img, translation_matrix, (img.shape[1], img.shape[0]))\n",
    "\n",
    "# translation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cv.imshow('translation_window', img)\n",
    "cv.createTrackbar('trackbar', 'translation_window', 2, 40, trackbar_translation)\n",
    "\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Rotation**\n",
    "\n",
    "Rotation is simple as changing the orientation of the image clockwise or anticlockwise, for rotation, we can use the rotation matrix to transform each pixes in some degree that simulates the rotation of the image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def trackbar_rotation(angle):\n",
    "    rotation_matrix = cv.getRotationMatrix2D(center, angle, scale = 1.0)\n",
    "    rotated_image = cv.warpAffine(img, rotation_matrix, (width, height))\n",
    "    cv.imshow('rotation_window', rotated_image)\n",
    "\n",
    "img = cv.imread('D:/OpenCV/Assets/newton.jpg')\n",
    "height, width = img.shape[0], img.shape[1]\n",
    "\n",
    "center = width // 2, height // 2\n",
    "\n",
    "cv.imshow('rotation_window', img)\n",
    "cv.createTrackbar('trackbar_rotation', 'rotation_window', 2, 180, trackbar_rotation)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Flipping**\n",
    "\n",
    "Flipping is simply the idea of making each pixes in reverse order. It makes the image upside down which can be done both horizontally and vertically.\n",
    "\n",
    "* Horizontal Flip: In horizontal flip, each row of pixes in the image if reversed, effectively flipping the image\n",
    "* Vertical Flip: It involves reversing each row of pixes vertically from top to bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('D:/OpenCV/Assets/newton.jpg')\n",
    "cv.imshow('flipping_window', img)\n",
    "\n",
    "while True:\n",
    "    k = cv.waitKey(0)\n",
    "    if k == ord('q'):\n",
    "        break\n",
    "    # Vertical Flipping\n",
    "    elif k == ord('v'):\n",
    "        img = cv.flip(img, 0)\n",
    "\n",
    "    # Horizontal Flipping\n",
    "    elif k == ord('h'):\n",
    "        img = cv.flip(img, 1)\n",
    "\n",
    "    cv.imshow('flipping_window', img)\n",
    "\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Shearing**\n",
    "\n",
    "Shearing is a kind of linear transformation where the shape of the object is changed to a parallelogram by shifting the points in a fixed direction by a amount proportional to the distance from the fixed line. Shearning can be vertical or horizontal\n",
    "\n",
    "* Horizontal shear: In horizontal shear, the image is transformed into a parallelogram by shifting the points in a fixed direction horizontally.\n",
    "* Vertical shear: Vertical shear involves transforming the image to a parallelogram by shifiting the points in a fixed direction vertically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def trackbar_shear_horizontal(x):\n",
    "    shear_factor = x / 5.0\n",
    "    shear_matrix = np.float32([[1, shear_factor, 0], [0, 1, 0]])\n",
    "    sheared_img = cv.warpAffine(img, shear_matrix, (img.shape[1], img.shape[0]))\n",
    "    cv.imshow('shear_window', sheared_img)\n",
    "\n",
    "\n",
    "def trackbar_shear_vertical(x):\n",
    "    shear_factor = x / 5.0\n",
    "    shear_matrix = np.float32([[1, 0, 0], [shear_factor, 1, 0]])\n",
    "    sheared_img = cv.warpAffine(img, shear_matrix, (img.shape[1], img.shape[0]))\n",
    "    cv.imshow('shear_window', sheared_img)\n",
    "\n",
    "\n",
    "img = cv.imread('D:/OpenCV/Assets/newton.jpg')\n",
    "cv.imshow('shear_window', img)\n",
    "cv.createTrackbar('trackbar_shear_h', 'shear_window', 2, 20, trackbar_shear_horizontal)\n",
    "cv.createTrackbar('trackbar_shear_v', 'shear_window', 2, 20, trackbar_shear_vertical)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Scaling**\n",
    "\n",
    "Scaling is a type of transformation for resizing the image whether to make it larger (zoom in) or smaller (zoom out). This transformation changes the size of the image but does not change the orientation or other types of properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trackbar_scaling(x):\n",
    "    scale_factor = x / 2 # Scale factor mapped to the range [0, 0.5]\n",
    "    \n",
    "    new_width = int(img.shape[1] * scale_factor)\n",
    "    new_height = int(img.shape[0] * scale_factor)\n",
    "\n",
    "    scaled_img = cv.resize(img, (new_width, new_height))\n",
    "\n",
    "    cv.imshow('scaling_window', scaled_img)\n",
    "\n",
    "img = cv.imread('D:/OpenCV/Assets/newton.jpg')\n",
    "cv.imshow('scaling_window', img)\n",
    "cv.createTrackbar('scaling_trackbar', 'scaling_window', 2, 5, trackbar_scaling)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. Image Arithmetic**\n",
    "\n",
    "Image arithmetic in OpenCV refers to the idea of adding, subtracting, multiplication, division, etc on pixel-wise. It allows to manipulate images by adding two images, blending, and others. This can be helpful in many situations.\n",
    "\n",
    "### **6.1 Adding two images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv.imread('D:/OpenCV/Assets/newton.jpg')\n",
    "img2 = cv.cvtColor(img1, cv.COLOR_BGR2HSV)\n",
    "\n",
    "added_img = cv.add(img1, img2)\n",
    "stacked_img = np.hstack([img1, img2, added_img])\n",
    "\n",
    "cv.imshow('window', stacked_img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6.2 Subtracting two images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv.imread('D:/OpenCV/Assets/newton.jpg')\n",
    "img2 = cv.cvtColor(img1, cv.COLOR_BGR2HSV)\n",
    "\n",
    "subtracted_img = cv.subtract(img1, img2)\n",
    "stacked_img = np.hstack([img1, img2, subtracted_img])\n",
    "\n",
    "cv.imshow('window', stacked_img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6.3 Multiplying two images**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv.imread('D:/OpenCV/Assets/newton.jpg')\n",
    "img2 = cv.cvtColor(img1, cv.COLOR_BGR2HSV)\n",
    "\n",
    "multiplied_img = cv.multiply(img1, img2)\n",
    "stacked_img = np.hstack([img1, img2, multiplied_img])\n",
    "\n",
    "cv.imshow('window', stacked_img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6.4 Dividing two images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv.imread('D:/OpenCV/Assets/newton.jpg')\n",
    "img2 = cv.cvtColor(img1, cv.COLOR_BGR2HSV)\n",
    "\n",
    "dividing_img = cv.divide(img1, img2)\n",
    "stacked_img = np.hstack([img1, img2, dividing_img])\n",
    "\n",
    "cv.imshow('window', stacked_img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7. Bitwise Operations**\n",
    "\n",
    "Bitwise operations in OpenCV are used for manipulating individual bits of pixels in images. It includes operations like:\n",
    "\n",
    "* AND\n",
    "* OR\n",
    "* NOT\n",
    "* XOR\n",
    "\n",
    "It works in individual pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rect = np.zeros((100, 100), np.uint8)\n",
    "cv.rectangle(rect, (15, 15), (85, 85), 255, -1)\n",
    "\n",
    "circle = np.zeros((100, 100), np.uint8)\n",
    "cv.circle(circle, center=(50, 50), radius=40, color = 255)\n",
    "\n",
    "\n",
    "bit_and = cv.bitwise_and(rect, circle)\n",
    "bit_or = cv.bitwise_or(rect, circle)\n",
    "bit_not = cv.bitwise_not(rect, circle)\n",
    "bit_xor = cv.bitwise_xor(rect, circle)\n",
    "\n",
    "img = np.hstack([rect, circle, bit_and, bit_or, bit_not, bit_xor])\n",
    "\n",
    "cv.imshow('window', img)\n",
    "cv.waitKey(0)\n",
    "\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **8. Masking**\n",
    "\n",
    "Masking is the technique of applying a specific operation on a specific region of image and considering the rest of the image as ignored. This can be done through a binary mask where the white pixels are where the operations is performed and the black pixels are where the operations are ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('D:/OpenCV/Assets/newton.jpg')\n",
    "\n",
    "mask = np.zeros_like(img)\n",
    "cv.rectangle(mask, pt1=(100, 70), pt2=(200, 200), color=(255, 255, 255), thickness = -1)\n",
    "\n",
    "# Applying the bitwise and for masking the region\n",
    "masked_img = cv.bitwise_and(img, mask)\n",
    "\n",
    "stacked_img = np.hstack([img, masked_img])\n",
    "\n",
    "cv.imshow('Masked', stacked_img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **9. Splitting**\n",
    "\n",
    "Splitting in terms of Computer Vision refers to segmenting or breaking down multi-colored images into various channels of same color. This will split the image into different 3 in case we are dealing with a RGB image. This is often used in computer vision tasks for feature extraction, color analysis and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('D:/OpenCV/Assets/newton.jpg')\n",
    "\n",
    "#cv.imshow('window', img)\n",
    "\n",
    "blue_channel, green_channel, red_channel = cv.split(img)\n",
    "\n",
    "stacked_channels = np.hstack([blue_channel, green_channel, red_channel])\n",
    "\n",
    "cv.imshow('window', stacked_channels)\n",
    "\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **10. Merging**\n",
    "\n",
    "So when splitting the image in case of RGB, we got three seperate channels, can we use this three seperate channels to produce the original image, we can do it using merge. Merge is used for combining the splitted channels to produce the original image. It can also be used to merge images to form colored images from seperate RGB images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will give us the original image in which the three images are formed\n",
    "merged_image = cv.merge((blue_channel, green_channel, red_channel))\n",
    "\n",
    "cv.imshow('window', merged_image)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
