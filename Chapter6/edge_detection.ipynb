{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Edge Detection**\n",
    "\n",
    "Edge detection is one of the common practices in computer vision which is the idea of detecting edges of different objects in image which has several applications like image segmentation, feature extraction, and other. Edge detection works by giving higher intesity to edges and supressing other values to the background.\n",
    "\n",
    "## **1.1 Laplacian Image Gradient For Edge Detection**\n",
    "\n",
    "The Laplacian image gradient is a popular technique in image processing and computer vision that is famously used for edge detection. It uses the Laplacian Operator to find the edges.\n",
    "\n",
    "The basic assumption is that the edges of a particular object in an image will strictly increase or decrease their intensity suddenly. Therefore, if we can differentiate the rate of change of the intensity of pixel values based on the space they are in the image, we can detect edges. However, for further improvement, we can use the second derivative of the image. Here we calculate how the rate of change of pixels changes according to the space they are in. This will give us higher values when we are at the boundaries of an object in the pixel, which helps to detect edges.\n",
    "\n",
    "For applying laplacian operator on an image, we convolve the image with a laplacian kernel, which is a small matrix representing the descrete approximation of laplacian operator.\n",
    "\n",
    "After performing convolution witht the laplacian kernel, we obtain a new image where the edges are enhanced and the backgorund noise is suppressed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "img = cv.imread('D:/OpenCV2/Assets/sudoku_paper.png', cv.IMREAD_GRAYSCALE)\n",
    "img2 = cv.Laplacian(img.copy(), ddepth=64)\n",
    "cv.imshow('window', np.hstack([img, img2]))\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.2 Canny Edge Detection**\n",
    "\n",
    "Canny Edge detection is one of the best and popular edge detection algorithm introduced by John F. Canny. It goes through several steps to finally obtain the image where the edges are perfectly marked. \n",
    "\n",
    "Here are the steps involved in Canny Edge Detection. \n",
    "\n",
    "1. **Convert the Image to Grayscale.**\n",
    "2. **Apply Gaussian blur.**\n",
    "3. **Apply Sobel Operator.**\n",
    "4. **Apply non-maximum supression.**\n",
    "5. **Apply Thresholding.**\n",
    "6. **Edge Tracking by histerisis.**\n",
    "\n",
    "Edge detection algorithms, specifically Canny Edge Detection, work under the assumption that high changes in intensity within an image indicate the presence of an edge. By calculating the **gradient** of a pixel in relation to its neighboring pixels both horizontally and vertically (Applying Sobel Operator), we can identify these sudden changes and accurately detect edges in the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.2.1 Converting the image to gray scale**\n",
    "\n",
    "Converting the image to grayscale before applying canny edge detection can be beneficial since grayscale images deal with two intensities, either high or low. This makes the process easier. Converting the image to gray scale can be simply done with opencv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('D:/OpenCV2/Assets/newton.jpg')\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "cv.imshow('window', gray)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.2.2 Applying Gaussian Blur**\n",
    "\n",
    "Gaussian blur is a technique used to normalize images and produce a blur effect that smoothens the image. But why do we need to apply it? \n",
    "\n",
    "When we consider a raw image, the edges and other parts might be very sharp and clear, which can lead to sudden intensity changes and affect edge detection. For example, when there are two edges close to each other, if we don't apply Gaussian blur before thresholding, the higher intensity edges will remove the lower intensity edges, which reduces the accuracy of edge detection. \n",
    "\n",
    "Therefore, applying Gaussian blur is a common approach before any edge detection task to ensure accurate and reliable results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('D:/OpenCV2/Assets/sudoku_paper.png')\n",
    "blurred = cv.GaussianBlur(img, (5, 5), 0)\n",
    "cv.imshow('window', blurred)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.2.3 Applying Sobel Operator**\n",
    "\n",
    "The Sobel Operator is a type of edge detection technique that detects edges by examining each pixel of an image and its horizontal and vertical neighboring pixels. It is essentially a 3x3 kernel that can be applied to an image to produce a gradient vector containing the values of intensity changes of pixels with respect to their neighboring pixels. \n",
    "\n",
    "Here's how it works:\n",
    "\n",
    "1. First, each individual pixel is examined one by one.\n",
    "2. For each pixel, we calculate the rate of change of that pixel with respect to its neighboring pixels both horizontally and vertically. This can be done by finding the derivatives of horizontal and vertical pixel changes with respect to the current pixel.\n",
    "3. After applying the kernel (Sobel Operator), we get a gradient vector.\n",
    "4. This gradient vector contains the rate of change in both horizontal and vertical directions.\n",
    "5. Finding the magnitude of this vector will give us information about the overall intensity of the current pixel with respect to its neighbors.\n",
    "6. The orientation/direction of this vector will give us information about where the intensity is increasing mostly, either in the horizontal direction or the vertical direction.\n",
    "7. Finally, we use the computed magnitude and plug it as the current pixel value. We'll place this value in the same pixel index or position of the new edge-detected image that we are going to create.\n",
    "\n",
    "Here are the Sobel kernels:\n",
    "\n",
    "Horizontal Sobel kernel:\n",
    "\n",
    "\\begin{bmatrix}\n",
    "-1 & 0 & 1 \\\\\n",
    "-2 & 0 & 2 \\\\\n",
    "-1 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "\n",
    "Vertical Sobel kernel:\n",
    "\n",
    "\\begin{bmatrix}\n",
    "-1 & -2 & -1 \\\\\n",
    "0 & 0 & 0 \\\\\n",
    "1 & 2 & 1\n",
    "\\end{bmatrix}\n",
    "\n",
    "After applying both of this for each of 3x3 window of an image, we'll get the gradient vector, Suppose, we got the gradient vector of a single pixel like this,\n",
    "\n",
    "\\begin{bmatrix}\n",
    "55 \\\\\n",
    "45\n",
    "\\end{bmatrix}\n",
    "\n",
    "To find the magnitude, you can use the Pythagores Theorem.\n",
    "\n",
    "$$\n",
    "\\text{Magnitude} = \\sqrt{{\\text{Horizontal\\_Gradient}}^2 + {\\text{Vertical\\_Gradient}}^2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Magnitude} = \\sqrt{{\\text{55}^2 + {\\text{45}^2}}} = 71.064\n",
    "$$\n",
    "\n",
    "We can round this magintude and apply to the new image same pixel position as of the original image.\n",
    "Doing this for each of the pixels will give us a new image which consists of detected edges.\n",
    "\n",
    "For finding the orientation, we can use the **arctan** of the ration between horizontal and vertical rate of change values in the gradient vector. \n",
    "\n",
    "Arctan is just the inverse of tangent function, we are performing arctan because we are interested in finding the angle between these two values, based on that angle, we can find the orientation of the gradient vector. Well, we know that,\n",
    "\n",
    "$$\n",
    "\\tan(\\theta) = \\frac{\\text{adjacent}}{\\text{opposite}}\n",
    "$$\n",
    "\n",
    "So if we have the values similar to adjacent and opposite side which is horizontal and vertical rate of change values, we could do,\n",
    "\n",
    "$$\n",
    "\\text{arctan}\\left(\\frac{\\text{opposite}}{\\text{adjacent}}\\right) = \\theta\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[   0.    0.    0.]\n",
      "  [  -8.   -8.   -8.]\n",
      "  [ -24.  -24.  -24.]\n",
      "  ...\n",
      "  [   0.    0.    0.]\n",
      "  [   0.    0.    0.]\n",
      "  [   0.    0.    0.]]\n",
      "\n",
      " [[   0.    0.    0.]\n",
      "  [ -15.  -15.  -15.]\n",
      "  [ -42.  -42.  -42.]\n",
      "  ...\n",
      "  [   0.    0.    0.]\n",
      "  [   0.    0.    0.]\n",
      "  [   0.    0.    0.]]\n",
      "\n",
      " [[   0.    0.    0.]\n",
      "  [ -31.  -31.  -31.]\n",
      "  [ -83.  -83.  -83.]\n",
      "  ...\n",
      "  [   0.    0.    0.]\n",
      "  [   0.    0.    0.]\n",
      "  [   0.    0.    0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[   0.    0.    0.]\n",
      "  [-128. -128. -128.]\n",
      "  [-357. -357. -357.]\n",
      "  ...\n",
      "  [   4.    4.    4.]\n",
      "  [   0.    0.    0.]\n",
      "  [   0.    0.    0.]]\n",
      "\n",
      " [[   0.    0.    0.]\n",
      "  [-128. -128. -128.]\n",
      "  [-359. -359. -359.]\n",
      "  ...\n",
      "  [   4.    4.    4.]\n",
      "  [   0.    0.    0.]\n",
      "  [   0.    0.    0.]]\n",
      "\n",
      " [[   0.    0.    0.]\n",
      "  [-128. -128. -128.]\n",
      "  [-360. -360. -360.]\n",
      "  ...\n",
      "  [   4.    4.    4.]\n",
      "  [   0.    0.    0.]\n",
      "  [   0.    0.    0.]]]\n",
      "[[[   0.    0.    0.]\n",
      "  [   0.    0.    0.]\n",
      "  [   0.    0.    0.]\n",
      "  ...\n",
      "  [   0.    0.    0.]\n",
      "  [   0.    0.    0.]\n",
      "  [   0.    0.    0.]]\n",
      "\n",
      " [[  -2.   -2.   -2.]\n",
      "  [  -9.   -9.   -9.]\n",
      "  [ -34.  -34.  -34.]\n",
      "  ...\n",
      "  [ -96.  -96.  -96.]\n",
      "  [ -96.  -96.  -96.]\n",
      "  [ -96.  -96.  -96.]]\n",
      "\n",
      " [[  -4.   -4.   -4.]\n",
      "  [ -13.  -13.  -13.]\n",
      "  [ -45.  -45.  -45.]\n",
      "  ...\n",
      "  [-116. -116. -116.]\n",
      "  [-116. -116. -116.]\n",
      "  [-116. -116. -116.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[   0.    0.    0.]\n",
      "  [   0.    0.    0.]\n",
      "  [  -1.   -1.   -1.]\n",
      "  ...\n",
      "  [  -4.   -4.   -4.]\n",
      "  [  -4.   -4.   -4.]\n",
      "  [  -4.   -4.   -4.]]\n",
      "\n",
      " [[   0.    0.    0.]\n",
      "  [   0.    0.    0.]\n",
      "  [  -1.   -1.   -1.]\n",
      "  ...\n",
      "  [  -4.   -4.   -4.]\n",
      "  [  -4.   -4.   -4.]\n",
      "  [  -4.   -4.   -4.]]\n",
      "\n",
      " [[   0.    0.    0.]\n",
      "  [   0.    0.    0.]\n",
      "  [   0.    0.    0.]\n",
      "  ...\n",
      "  [   0.    0.    0.]\n",
      "  [   0.    0.    0.]\n",
      "  [   0.    0.    0.]]]\n"
     ]
    }
   ],
   "source": [
    "gradient_x = cv.Sobel(src=blurred, ddepth=cv.CV_64F, dx=1, dy=0, ksize = 3)\n",
    "gradient_y = cv.Sobel(blurred, cv.CV_64F, dx=0, dy=1, ksize=3)\n",
    "\n",
    "\n",
    "print(gradient_x)\n",
    "print(gradient_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.2.4 Non-Maximum Supression**\n",
    "\n",
    "The Sobel Operator is a commonly used method to find edges in an image, but it has a limitation. The resulting image may contain thick and dispersed edges since Sobel does not consider the thickness of the edges. To address this issue, we can apply non-maximum suppression to the resulting image obtained after applying the Sobel operator.\n",
    "\n",
    "Non-maximum suppression works by suppressing pixel values that have lower intensity than the global maximum intensity values. In other words, intensities that are lower than the maximum intensity of the image are converted to zero. The global maximum intensity represents where the edges are located, so removing the remaining intensities makes sense.\n",
    "\n",
    "This process involves examining neighboring intensities and the direction in which they are increasing or decreasing. Based on this information, we can determine which pixel intensities to suppress and which ones to keep.\n",
    "\n",
    "### **1.2.5 Thresholding**\n",
    "\n",
    "In this step, we choose a threshold value to adjust the brightness of certain pixels in an image. The pixels on the edges of the image need to be brighter while the others need to be dimmer. This is because the values of the pixels on the edges are usually greater than the values of the other pixels. By applying thresholding, we can enhance the edges of the image based on a specific threshold value.\n",
    "\n",
    "### **1.2.6 Edge Tracking by histerisis**\n",
    "\n",
    "This is the last and final step which involves tracking the edges. This step if optional but is preferd since it will give more clarity to edges. The idea behind edge tracking by hysteresis is to link adjacent edge pixels to form continuous edges and suppress isolated edge pixels that may be noise.\n",
    "\n",
    "The process begins by classifying the edges into three categories based on their gradient magnitude:\n",
    "\n",
    "* Strong Edges: Pixels with gradient magnitudes above a high threshold.\n",
    "* Weak Edges: Pixels with gradient magnitudes between a low and high threshold.\n",
    "* Non-Edges: Pixels with gradient magnitudes below a low threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = cv.Canny(img, threshold1=50, threshold2=100)\n",
    "\n",
    "cv.imshow('window', edges)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
